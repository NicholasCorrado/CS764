        % % Title and author(s)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{Accelerating Joins with Filters}
\author{Nicholas Corrado \and Xiating Ouyang}
\date{}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[10pt]{article}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% %
% % The next command allows your in import encapsulated
% % postscript files, .epsf or .eps files, which
% % contain vector graphic image data.
% %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{graphicx}
\usepackage{charter,eulervm}
\usepackage{simpleConference}
%\renewcommand{\baselinestretch}{1.5}
\setcounter{secnumdepth}{3} % default value for 'report' class is "2"
\usepackage{amsthm,amsmath,amssymb,upgreek,marvosym,mathtools}
\usepackage{array}
\usepackage{makeidx}  % allows for indexgeneration
\usepackage{paralist}
\usepackage{subfig}
\usepackage{tabularx}
\usepackage{tabu}
\usepackage{comment}
\usepackage[nottoc]{tocbibind}
\usepackage[usenames,dvipsnames]{color}
\usepackage[pdftex,breaklinks,colorlinks,citecolor={blue}, linkcolor={blue},urlcolor=Maroon]{hyperref}
\usepackage{tkz-graph}
 \linespread{1.25}
\usetikzlibrary{automata, positioning,arrows,shapes,decorations.pathmorphing}

 \tikzset{
->, % makes the edges directed
>=stealth, % makes the arrow heads bold
node distance=3cm, % specifies the minimum distance between two nodes. Change if necessary.
every state/.style={thick, fill=gray!10}, % sets the properties for each ’state’ node
initial text=$ $, % sets the text that appears on the start arrow
}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{reduction}{Reduction}[section]
\newtheorem{proposition}{Proposition}[section]
\newtheorem{scolium}{Scolium}[section]   %% And a not so common one.
\newtheorem{definition}{Definition}[section]
\newtheorem{conjecture}{Conjecture}[section]
\newtheorem{corollary}{Corollary}[section]
%\newenvironment{proof}{{\sc Proof:}}{~\hfill QED}
\newenvironment{AMS}{}{}
\newenvironment{keywords}{}{}
\DeclarePairedDelimiter{\norm}{\lVert}{\rVert}
\newcommand{\todo}{(TO BE CONTINUED...)}
\graphicspath{ {./pics/} }

\newcommand{\paris}[1]{{\color{blue} Paris: [{#1}]}}

\newcommand{\xiating}[1]{{\color{blue} Xiating: [{#1}]}}


\newcommand{\trans}[1]{
	#1^\mathsf{T}
}

\newcommand{\db}{$\mathbf{db}$}
\newcommand{\sjfq}{\texttt{sjfCQA}}
\newcommand{\bcq}{\texttt{bcq}}
\newcommand{\problem}[1]{\textsc{certainty}($#1$)}
\newcommand{\FO}{$\mathbf{FO}$}
\newcommand{\PTIME}{$\mathbf{P}$}
\newcommand{\LSPACE}{$\mathbf{L}$}
\newcommand{\coNP}{$\mathbf{coNP}$}
\newcommand{\und}[1]{\underline{#1}}
\newcommand{\NL}{$\mathbf{NL}$}
\newcommand{\JOIN}{\bowtie}

\begin{document}
\newpage
\maketitle


\abstract{In query optimization on star schemas, lookahead information passing (LIP) is a strategy exploiting the efficiency of probing succinct filters to eliminate practically all facts that do not appear in the final join results before performing the actual join. Assuming data independency across all columns in the fact table, LIP achieves efficient and robust query optimization. We present LIP-$k$, a variant of LIP that only remembers the hit/miss statistics for the previous $k$ batches, achieving empirically efficient query execution on fact table with correlated and even adversarial data columns. We implemented LIP and LIP-$k$ on a skeleton database on top of Apache Arrow and analyze the performance of each variant of LIP using the notion of competitive ratio in online algorithms.}

\input{introduction}

\input{lip}

\input{implementation}

\input{empirical}


\section{Future Works and Concluding Remarks}

The contributions of this project come in two-folds: We implemented Hash-join and LIP on top of Apache Arrow and thus provided an interface for future integration of Hustle on Apache Arrow; and we proposed LIP-$k$, a variant of LIP, which opens up an area for improving the performance LIP. 
We find that for certain queries, 
LIP-$k$ performs better than LIP, 
while for other queries,
LIP performs better than LIP-$k$.

The budget allowed for filtering each tuple is limited --- roughly 100 CPU cycles. Hence, computationally-heavy approaches to maintaining filter statistics are not practically beneficial. Therefore, we will investigate dynamically sampling a segment of the fact table to have true estimates of each filters, and then stick to this estimate for the next few batches. This has low maintenance overhead, and once the adaptive policy for dynamic sampling is established, we expect that to have better practical performance than LIP and LIP-$k$. Note that this strategy is still deterministic, still prone to the worst case $n$ competitive ratio bound established by Theorem~\ref{thm:det-n}.  
It would be interesting to study LIP in the online algorithmic setting to design an efficient mechanism utilizing randomness 
that offers better worst-case guarantees without burning too many CPU cycles.
Of course, CPU efficiency and randomness are at odds in such an approach. 

As discussed in Section~\ref{sec:time}, sometimes the inherent cost of aiming for the optimal filter sequence outweighs its benefit.
In such cases, it is better to simply aim for ``good enough".
With this in mind, it would be interesting to develop a variant of LIP that strives for ``good enough" rather than optimality.


% Future work below

% In this work, there exists an adversarial fact table for all variants of LIP have that would force the algorithm to achieve a competitive ratio of $n$. However, reasonable applications of some existing random online algorithm mechanisms may yield a competitive ratio of $O(\log n)$ using the weighted majority algorithm \cite{littlestone1994weighted}. However, multiplicative updates on the weights may change the weighted average filter to use, but will not change the sequence of all filters if only comparing them based on their weights. More work is required here to either provide a mechanism to achieve a better competitive ratio, or provide a lower bound reduction showing that the competitive ratio of $n$ is tight even for random mechanisms.


\section*{Acknowledgements}

The authors wish to thank Prof.\ Jignesh Patel for providing constant feedback on this project and Kevin Gaffney for helping us with Apache Arrow specifics. The second author wishes to thank Prof.\ Paris Koutris for the suggestion of working on a practical project when the lemma production pipe is jammed. It works.


\bibliographystyle{plain}
\bibliography{rep}


\end{document}
