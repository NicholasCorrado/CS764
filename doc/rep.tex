        % % Title and author(s)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{Topics in Database Management Systems Project Report: Skipping Filters is Almost Optimal}
\author{Nicholas Corrado \and Xiating Ouyang}
\date{}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[10pt,twocolumn]{article}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% %
% % The next command allows your in import encapsulated
% % postscript files, .epsf or .eps files, which
% % contain vector graphic image data.
% %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{graphicx}
%\usepackage{charter,eulervm}
\usepackage{simpleConference}
%\renewcommand{\baselinestretch}{1.5}
\setcounter{secnumdepth}{3} % default value for 'report' class is "2"
\usepackage{amsthm,amsmath,amssymb,upgreek,marvosym,mathtools}
\usepackage{array}
\usepackage{makeidx}  % allows for indexgeneration
\usepackage{paralist}
\usepackage{subfig}
\usepackage{tabularx}
\usepackage{tabu}
\usepackage{comment}
\usepackage[nottoc]{tocbibind}
\usepackage[usenames,dvipsnames]{color}
\usepackage[pdftex,breaklinks,colorlinks,citecolor={blue}, linkcolor={blue},urlcolor=Maroon]{hyperref}
\usepackage{tkz-graph}
\usepackage{geometry}
 \geometry{
 a4paper,
 total={170mm,257mm},
 left=25mm,
 top=20mm,
 right=25mm,
 }
\usetikzlibrary{automata, positioning,arrows,shapes,decorations.pathmorphing}

 \tikzset{
->, % makes the edges directed
>=stealth, % makes the arrow heads bold
node distance=3cm, % specifies the minimum distance between two nodes. Change if necessary.
every state/.style={thick, fill=gray!10}, % sets the properties for each ’state’ node
initial text=$ $, % sets the text that appears on the start arrow
}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{reduction}{Reduction}[section]
\newtheorem{proposition}{Proposition}[section]
\newtheorem{scolium}{Scolium}[section]   %% And a not so common one.
\newtheorem{definition}{Definition}[section]
\newtheorem{conjecture}{Conjecture}[section]
\newtheorem{corollary}{Corollary}[section]
%\newenvironment{proof}{{\sc Proof:}}{~\hfill QED}
\newenvironment{AMS}{}{}
\newenvironment{keywords}{}{}
\DeclarePairedDelimiter{\norm}{\lVert}{\rVert}
\newcommand{\todo}{(TO BE CONTINUED...)}

\newcommand{\paris}[1]{{\color{blue} Paris: [{#1}]}}


\newcommand{\trans}[1]{
	#1^\mathsf{T}
}

\newcommand{\db}{$\mathbf{db}$}
\newcommand{\sjfq}{\texttt{sjfCQA}}
\newcommand{\bcq}{\texttt{bcq}}
\newcommand{\problem}[1]{\textsc{certainty}($#1$)}
\newcommand{\FO}{$\mathbf{FO}$}
\newcommand{\PTIME}{$\mathbf{P}$}
\newcommand{\LSPACE}{$\mathbf{L}$}
\newcommand{\coNP}{$\mathbf{coNP}$}
\newcommand{\und}[1]{\underline{#1}}
\newcommand{\NL}{$\mathbf{NL}$}
\newcommand{\JOIN}{\bowtie}

\begin{document}
\newpage
\maketitle


\abstract{}


\section{Introduction}

Performing join operations in database management systems based on Star Schema is increasingly becoming a fundamental task in modern data industries. Various efforts have been spent on building a reliable query optimizer. However, the current optimizers may still produce highly inefficient query plans which involves processing unnecessarily gigantic intermediate tables \cite{leis2015good,rabl2013variations}. \textit{Lookahead Information Passing (LIP)} aggressively uses Bloom Filters to filter the fact tables to effectively reduce the sizes of the intermediate tables, provably as efficient and robust as computing the join using the optimal query plan \cite{zhu2017looking}. 


However, the cost of LIP is the huge amount of memory and cache used to store the set of LIP filters: Replacing the LIP filters in cache for a new LIP filter causes significant delay, and if the new LIP filter is not selective skipping it might improve the performance.

This project aims at investigating the effect of skipping certain LIP filter on improving the performance of LIP, and if possible, derive a theoretical guarantee on the performance of LIP against the optimal joining sequence. 



\section{Lookahead Information Passing (LIP)}

Let $F$ be the fact table and $D_i$ the dimension tables for $1 \leq i \leq n$. We denote the number of facts in $F$ and each $D_i$ as $|F|$ and $|D_i|$. A LIP filter on $D_i$ is implemented using a Bloom filter, with false positive rate $\varepsilon$. The true selectivity $\sigma_i$ of $D_i$ on fact table $F$ is given by $\sigma_i = |D_i \JOIN_{pk_i = fk_i} F| / |F|,$ where $pk_i$ is the primary key of $D_i$ and $fk_i$ is the foreign key of $D_i$ in $F$. The \texttt{LIP-join} algorithm, depicted in Figure \ref{fig:lip}, computes the indices of tuples in $F$ that pass the filtering of each Bloom filter of $D_i$. Note that there is an innate false positive rate $\varepsilon$ associated with each Bloom Filter, and thus the set of indices is a superset of the true set of indices of tuples appearing in the final join result.

The partition in \cite{zhu2017looking} satisfies that $|F_{t+1}| = 2|F_{t}|$ at line 5, and the algorithm approximates the true selectiveness $\sigma_i$ of each dimension $D_i$ using $pass[i]/count[i]$, the aggregated selectiveness since the beginning.

\begin{figure*}[h!]
	\centering
	\tikz\path (0,0) node[draw, text width=.8\textwidth, rectangle, inner xsep=20pt, inner ysep=10pt]{
		\begin{minipage}[t!]{\textwidth}
			{\sc Procedure}: \texttt{LIP-join}
			\\
			{\sc Input}: a fact table $F$ and a set of $n$ Bloom filters $f_i$ for each $D_i$ with $1 \leq i \leq n$
 			\\
			{\sc Output}: Indices of tuples in $F$ that pass the filtering
			\begin{tabbing}
				Aaa\=aaA\=Aaa\=Aaa\=Aaa\=AAAAAAAAAAAAAAAAAAAAAAAAA\=A \kill
				1.\> Initialize $I = \emptyset$
				\\
				2.\> {\bf foreach } filter $f$ {\bf do}
				\\
				3.\>\> $count[f] \leftarrow 0$
				\\
				4.\>\> $pass[f] \leftarrow 0$ 
				\\
				5.\> Partition $F = \bigcup_{1 \leq t \leq T}F_t$. 
				\\
				6.\> {\bf foreach } fact block $F_t$ {\bf do} 
				\\
				7.\>\> {\bf foreach } filter $f$ in order {\bf do}
				\\
				8.\>\>\> {\bf foreach} index $j \in F_t$ {\bf do}
				\\
				9.\>\>\>\> $count[f] \leftarrow count[f] + 1$
				\\
				10.\>\>\>\> {\bf if }$f$ contains $F_t[j]$ 
				\\
				11.\>\>\>\>\> $I \leftarrow I \cup \{j\}$ 
				\\
				12.\>\>\>\>\> $pass[f] \leftarrow pass[f] + 1$
				\\
				13.\>\> {\bf sort} filters $f$ in nondesending order of $pass[f]/count[f]$
				\\
				14.\> {\bf return } $I$
			\end{tabbing}  
		\end{minipage}
	};
	\caption{The LIP algorithm for computing the joins.}
	\label{fig:lip}
\end{figure*}


\subsection{Discussions}

LIP algorithm in Figure \ref{fig:lip} estimates the selectivity of each filter using statistics from the very beginning, which is inefficient for certain distribution and physical layout of data. Consider some filter $f$ that is very selective for the first $t_0$ iterations at line 6 and not selective for the remaining iterations. (For example, a filter $f$ filtering for \texttt{year} $\geq 2017$ and the \texttt{Date} table is sorted in \texttt{year}.) In this case, LIP would obtain a good estimate of the selectivity of $f$ during the first $t_0$ iterations, and thus tend to apply $f$ early in the remaining iterations. However, it is in fact more efficient to postpone applying $f$ in the remaining iterations, despite $f$ has good selectivity in the first $t_0$ iterations. One remedy to this is to only ``remember" the hit/miss statistics of each filter over the previous $t^*$ iterations, mitigating the effect of such long-term influence.


Experimental results suggest that the speedup achieved by using LIP is concave with respect to the number of LIP filters used. Such concavity arises largely due to the fact that when more filters are applied, the cache is constantly replacing the filters, resulting a replacement overhead. 


\section{Our Work}

We are building a \textit{minimal} prototype of a database system on top of apache arrow supporting only selection and join as the basic operations using hash-join and LIP-join to model any database system. Then we will implement our revised versions of LIP-join and measure the performance. 

The dataset is obtained from the Star Schema Benchmark \cite{o2009star}. We will hard-code each queries in \cite{o2009star} to measure the join processing time.




\section{Current Progress}

We are implementing a traditional hash-join algorithm and the \texttt{LIP-join} algorithm on top of apache arrow in C++. The code is available at \url{https://github.com/NicholasCorrado/CS764}. Our implementation is meant to be a prototype to model any database system running hash-join and LIP-join and experiment with multiple variants of LIP. 

We have finished implementing the hash-join algorithm and the LIP filters.


\section*{Acknowledgement}
The authors wish to thank Prof.\ Jignesh Patel for constant feedback on this project and Kevin for helping us in coding with apache arrow.
% \section{Skipping LIP Filters}

% In this section, we present our modified \texttt{LIP-join-skip} algorithm and discuss some implementation details.

% \subsection{Implementation}

% We implemented the traditional hash-join algorithm, the \texttt{LIP-join} algorithm and our modified \texttt{LIP-joip-skip} on top of apache arrow in C++. The code is available at \url{https://github.com/NicholasCorrado/CS764}.


% \section{Experiments}


\begin{comment}
\section{Deploying lookahead filters in distributed systems}

In this section we discuss a method to deploy the LIP filters in distributed systems. This method incorporates LIP and the \textsc{hypercube} algorithm \cite{zhu2017looking,}.


Let $p$ be the number of machines available. Let $k_i$ be the primary key of $D_i$, and each tuple in the fact table $F$ possesses a foreign key to each $D_i$. Suppose $p = \prod_{1 \leq i \leq n} p_i$,  and then we label each of the $p$ machines with a coordinate $(x_1, x_2, \dots, x_n)$ where each $1 \leq x_i \leq p_i$.

We first pick $n$ hash functions $h_i$ such that the range of each $h_i$ is $\{1, 2, \dots, p_i\}$. Then for each dimension table $D_i$ and for each primary key $k_i$ in $D_i$, we send $k_i$ to all machines with $i$-th component being $h_i(k_i)$. 

\end{comment}


% \section{Concluding remarks}

\section{Future works}

Once we finish implementing hash-join and LIP-join, we will start testing our proposed variants of LIP and evaluate their performance against the optimal joining sequence of hash-join. Since the project is aimed at improving LIP, we will measure the performance of the optimal hash-join sequence by enumerating all joining sequences, and compare our revised LIP algorithm against it. 



\bibliography{rep}{}
\bibliographystyle{plain}

\end{document}
