

\section{Database Implementation}

We have developed a prototype database system supporting basic select and join operations on top of Apache Arrow \cite{apachearrow}, a column-store format. This minimal prototype is sufficient to benchmark the performance of our Hash join, LIP, and LIP-$k$.

Our implementations of LIP and LIP-k only support left-deep join tree plans where the fact table is the ``outer table" in every join. We assume that the fact table schema contains foreign keys to all dimension tables, and each dimension table is single-key. Given a star schema fact table $F$ and dimension tables $D_i$ for $1 \leq i \leq n$, a join query in our system specifies selectors $\sigma_F$ for $F$ and $\sigma_i$ for each $D_i$, and executing that query will return 

$$\sigma_F(F) \JOIN \sigma_1(D_1) \JOIN \dots \JOIN \sigma_n(D_n)$$

\noindent projected on the schema of $F$, {\it i.e.}~we output the tuples in $F$ that can be joined with each $D_i$. The supported primitive selectors allow for selection ($=, \leq, \geq, <, >$) on scalar values and ranges. Range selections are executed using \texttt{BETWEEN} ($\ell$, $h$), which selects all $x$ with $\ell \leq x \leq h$. 

The selectors for each dimension can be either a primitive selector consisting of simple predicate ({\it e.g.} \texttt{ORDER DATE} = 1997) 
or a composition (logical AND/OR) of multiple primitive/composite selectors. 
This is implemented using the Composite design pattern.
Apache Arrow does not yet support vectorized string comparison operations nor vectorized range comparison operations.
For queries involving string and/or range selections, 
we instead scan along the column, checking which rows satisfy the selection predicate. 
Such selections are inherently slower than the supported vectorized selections. 
Because all of our join implementations must implement row-wise selection for string and range predicates, 
all algorithms suffer the same slowdown. 
Thus, this implementation caveat does not preclude us from studying the relative performance of LIP and LIP-$k$.

We only support string and numeric data types. All numeric data is stored as 64-bit integers by default.

The hash join algorithm first produces a hash table $T_i$ for each $\sigma_i(D_i)$, projected on the $k_i$, and then probe each tuple in the fact table against all $T_i$. We used Sparseepp (accessible at \url{https://github.com/greg7mdp/sparsepp}) as our implementation of the hash table, in which the sparsehash by Google (accessible at \url{https://github.com/sparsehash/sparsehash}) is used as the underlying hash function. All primary keys are regarded as 64-bit integers.

For LIP and LIP-$k$, the succinct filter structure we choose is the Bloom filters. 
The default false-positive rate is set to 0.001, which requires 10 hash functions.
We use Knuth's Multiplicative hash function, extended to accept a 64-bit integer as a seed. 
Our minimal implementation does not support selectivity estimation, 
so we initialize each Bloom filter assuming $\sigma(D_i) = \frac{1}{2}$, 
{\it i.e.} assuming half of the keys in each dimension table will be inserted into the filter.

Our code is available at \url{https://github.com/NicholasCorrado/CS764}.


